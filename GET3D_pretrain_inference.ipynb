{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mapoto/get3d-test-face/blob/main/GET3D_pretrain_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lQzCi3XbxPBB",
        "outputId": "82a8a32e-7aee-4a07-9f02-3001e97d0e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GET3D'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 195 (delta 11), reused 10 (delta 10), pack-reused 172\u001b[K\n",
            "Receiving objects: 100% (195/195), 175.40 MiB | 43.52 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n",
            "/content/GET3D\n",
            "--2022-10-13 18:47:23--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/metrics/inception-2015-12-05.pkl\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 52.9.210.224, 52.8.99.141\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|52.9.210.224|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 \n",
            "Location: https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/metrics/inception-2015-12-05.pkl?response-content-disposition=attachment%3B%20filename%3D%22inception-2015-12-05.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQDBiyUqjLy50GyicSMJKjNR0Lj2ll%2BAkNeaw9jzQMGpCgIhAPI%2FzoG4TQLTJBUsB6iMMTuw5enQELnM26AVI0AjFD%2FsKtUECKv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBBoMNzg5MzYzMTM1MDI3IgzYMkk4QFeDJdAkZXIqqQSXM7tHADV%2FON7lbcGdsDzcWxo8qiPA4W7n2G01iSIfGJPrvito8Mzl1hdFG%2BDtffOg5UFjJ06cdRwaq7Aa5lqeYgh44CSY6jIMpF0ac%2F%2FvbJ8DjGhS6hSw8A85NgEmkMXdQf6jSnldhCVwVKZEVKEaDDMN7GWanc1Ry3IiooInVdFn%2Fn%2BndLuVoZkk3viG4a1csQ0zhREBq57lmYvyAAuS%2FW%2Frs8Y4RnoDUXZk2ZYWEMhKEcuIBlgFNiv082LOQXAD9OLsL5aJU4nqItqcfGkz7pREq6Q0NG9B6N%2FCte1y%2BxIh8FtlpcI7xQedEo3LmLX7Pispj7eOXcxrORKTTfMh0P6S34WWalq7q81BdBR53tRgQkitz6WjoMwQsZTdEv1fMW2uWhtlhKBUQLwuImfXsI%2BrDYVZSP60lUsO%2BwjaA5yDUcED84n2weXSnuh5yPgiTPit47pBRC3NLv5QeZn5c3KC13ytRX84L8h11cZk2T8u46ID4YY%2Bz439urmoU1oMs%2FhfEEcXuuF2Ca7f9mfEkzXKIW0ulBZ8BeTwrVfVzeR8QOhZWUbAojOj7OjrT0vT1pNyqth%2BwbB4cFF8YabDsGMqa%2FEmaYTjQqEHyTXN2UPRVhiLfbwKosZaXf5ia1u92PYNxIHy31cw3gK9%2BWP6LnlEyYEZmKbrKKk7uGWGbR7%2BZPk%2B2120yqJks0slP%2FBRecb3%2FxwKGSY%2FZZI6AKPoFog7WSpCG7UbMI6ioZoGOqgBo2f1I9wb8Jsa0Rou1Gtf3dhTA2jZGcerZTeTb5zQLc3RbXm1keahJO4KYELFAcadIjArXu7yGwxhTFYL2QKHSGG9JJky4cC3wEZRcwLHwBlcaviLhD9WRrKupx7MvZdkAMSqXIACF1o4M0%2B05Ve%2FYkcEuDAPxxweRlGTPqwiW3Nls8V2IFi%2B5Yd0pxIxZfxPJKW%2B3SF%2BE4FjuaBBzIdaTJDlHXMY1CBC&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20221013T184724Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZREEQRDCW%2F20221013%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=140b58b94a76cd633382943c059b2ed5864e1f139b2ade9058f4e8d36e3da3c4 [following]\n",
            "--2022-10-13 18:47:24--  https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/metrics/inception-2015-12-05.pkl?response-content-disposition=attachment%3B%20filename%3D%22inception-2015-12-05.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQDBiyUqjLy50GyicSMJKjNR0Lj2ll%2BAkNeaw9jzQMGpCgIhAPI%2FzoG4TQLTJBUsB6iMMTuw5enQELnM26AVI0AjFD%2FsKtUECKv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBBoMNzg5MzYzMTM1MDI3IgzYMkk4QFeDJdAkZXIqqQSXM7tHADV%2FON7lbcGdsDzcWxo8qiPA4W7n2G01iSIfGJPrvito8Mzl1hdFG%2BDtffOg5UFjJ06cdRwaq7Aa5lqeYgh44CSY6jIMpF0ac%2F%2FvbJ8DjGhS6hSw8A85NgEmkMXdQf6jSnldhCVwVKZEVKEaDDMN7GWanc1Ry3IiooInVdFn%2Fn%2BndLuVoZkk3viG4a1csQ0zhREBq57lmYvyAAuS%2FW%2Frs8Y4RnoDUXZk2ZYWEMhKEcuIBlgFNiv082LOQXAD9OLsL5aJU4nqItqcfGkz7pREq6Q0NG9B6N%2FCte1y%2BxIh8FtlpcI7xQedEo3LmLX7Pispj7eOXcxrORKTTfMh0P6S34WWalq7q81BdBR53tRgQkitz6WjoMwQsZTdEv1fMW2uWhtlhKBUQLwuImfXsI%2BrDYVZSP60lUsO%2BwjaA5yDUcED84n2weXSnuh5yPgiTPit47pBRC3NLv5QeZn5c3KC13ytRX84L8h11cZk2T8u46ID4YY%2Bz439urmoU1oMs%2FhfEEcXuuF2Ca7f9mfEkzXKIW0ulBZ8BeTwrVfVzeR8QOhZWUbAojOj7OjrT0vT1pNyqth%2BwbB4cFF8YabDsGMqa%2FEmaYTjQqEHyTXN2UPRVhiLfbwKosZaXf5ia1u92PYNxIHy31cw3gK9%2BWP6LnlEyYEZmKbrKKk7uGWGbR7%2BZPk%2B2120yqJks0slP%2FBRecb3%2FxwKGSY%2FZZI6AKPoFog7WSpCG7UbMI6ioZoGOqgBo2f1I9wb8Jsa0Rou1Gtf3dhTA2jZGcerZTeTb5zQLc3RbXm1keahJO4KYELFAcadIjArXu7yGwxhTFYL2QKHSGG9JJky4cC3wEZRcwLHwBlcaviLhD9WRrKupx7MvZdkAMSqXIACF1o4M0%2B05Ve%2FYkcEuDAPxxweRlGTPqwiW3Nls8V2IFi%2B5Yd0pxIxZfxPJKW%2B3SF%2BE4FjuaBBzIdaTJDlHXMY1CBC&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20221013T184724Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZREEQRDCW%2F20221013%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=140b58b94a76cd633382943c059b2ed5864e1f139b2ade9058f4e8d36e3da3c4\n",
            "Resolving prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)... 52.218.246.161\n",
            "Connecting to prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)|52.218.246.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95617399 (91M) [application/octet-stream]\n",
            "Saving to: ‘inception-2015-12-05.pkl’\n",
            "\n",
            "inception-2015-12-0 100%[===================>]  91.19M  29.8MB/s    in 3.1s    \n",
            "\n",
            "2022-10-13 18:47:28 (29.8 MB/s) - ‘inception-2015-12-05.pkl’ saved [95617399/95617399]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 1.3 MB/s eta 0:15:21tcmalloc: large alloc 1147494400 bytes == 0x394dc000 @  0x7f1445273615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.3 MB/s eta 0:13:05tcmalloc: large alloc 1434370048 bytes == 0x7db32000 @  0x7f1445273615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.3 MB/s eta 0:09:16tcmalloc: large alloc 1792966656 bytes == 0x2964000 @  0x7f1445273615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:04:56tcmalloc: large alloc 2241208320 bytes == 0x6d74c000 @  0x7f1445273615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf30ae000 @  0x7f14452721e7 0x4b2150 0x4b21dc 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5\n",
            "tcmalloc: large alloc 2551685120 bytes == 0x1e102c000 @  0x7f1445273615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x4ba899 0x4d29f9\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 7.1 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 37.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 25.6 MB/s \n",
            "\u001b[?25hCollecting xatlas\n",
            "  Downloading xatlas-0.0.6-cp37-cp37m-manylinux2010_x86_64.whl (207 kB)\n",
            "\u001b[K     |████████████████████████████████| 207 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: xatlas, ninja\n",
            "Successfully installed ninja-1.10.2.4 xatlas-0.0.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/NVlabs/nvdiffrast/\n",
            "  Cloning https://github.com/NVlabs/nvdiffrast/ to /tmp/pip-req-build-4sv3w3jw\n",
            "  Running command git clone -q https://github.com/NVlabs/nvdiffrast/ /tmp/pip-req-build-4sv3w3jw\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nvdiffrast==0.3.0) (1.21.6)\n",
            "Building wheels for collected packages: nvdiffrast\n",
            "  Building wheel for nvdiffrast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvdiffrast: filename=nvdiffrast-0.3.0-py3-none-any.whl size=140213 sha256=1ed501b2c815109acef52abcc95477e4a9decf5e18997a81254e1062f8611b8b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-poo0cat3/wheels/03/16/0a/c5fbe197e3519adf568dd98719becee0fc7999e1787ffdf688\n",
            "Successfully built nvdiffrast\n",
            "Installing collected packages: nvdiffrast\n",
            "Successfully installed nvdiffrast-0.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting meshzoo\n",
            "  Downloading meshzoo-0.9.14-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 28.1 MB/s \n",
            "\u001b[?25hCollecting ipdb\n",
            "  Downloading ipdb-0.13.9.tar.gz (16 kB)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Collecting point-cloud-utils\n",
            "  Downloading point_cloud_utils-0.27.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 48.7 MB/s \n",
            "\u001b[?25hCollecting imageio-ffmpeg==0.4.4\n",
            "  Downloading imageio_ffmpeg-0.4.4-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting pyspng==0.1.0\n",
            "  Downloading pyspng-0.1.0-cp37-cp37m-manylinux2010_x86_64.whl (195 kB)\n",
            "\u001b[K     |████████████████████████████████| 195 kB 71.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyspng==0.1.0) (1.21.6)\n",
            "Collecting x21<0.4.0,>=0.3.3\n",
            "  Downloading x21-0.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting kgt\n",
            "  Downloading kgt-0.4.7-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from ipdb) (57.4.0)\n",
            "Collecting ipython>=7.17.0\n",
            "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 65.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from ipdb) (0.10.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (5.1.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (4.8.0)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 65.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (2.6.1)\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.17.0->ipdb) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.17.0->ipdb) (0.7.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb) (0.2.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio) (7.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from point-cloud-utils) (1.7.3)\n",
            "Collecting PyNaCl\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 70.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.7/dist-packages (from kgt->meshzoo) (2.0.1)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from kgt->meshzoo) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kgt->meshzoo) (2.23.0)\n",
            "Collecting rich\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 63.5 MB/s \n",
            "\u001b[?25hCollecting tomli-w\n",
            "  Downloading tomli_w-1.0.0-py3-none-any.whl (6.0 kB)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 66.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->kgt->meshzoo) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->kgt->meshzoo) (2.21)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kgt->meshzoo) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->kgt->meshzoo) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kgt->meshzoo) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->kgt->meshzoo) (2022.9.24)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from rich->kgt->meshzoo) (4.1.1)\n",
            "Building wheels for collected packages: ipdb, gputil\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.9-py3-none-any.whl size=11648 sha256=878336aad4f62f803fbfb8b7f6a802488aa1710af59e528215911b28c8a250ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/cd/cc/aaf92acae337a28fdd2aa4d632196a59745c8c39f76eaeed01\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=c976e6346e3f8334e24f40c99a80a3a662acb51aaa0181c415214b079b06bddc\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built ipdb gputil\n",
            "Installing collected packages: commonmark, x21, tomli-w, rich, PyNaCl, matplotlib-inline, jedi, cryptography, kgt, ipython, pyspng, point-cloud-utils, meshzoo, ipdb, imageio-ffmpeg, gputil\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.9.0\n",
            "    Uninstalling ipython-7.9.0:\n",
            "      Successfully uninstalled ipython-7.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n",
            "Successfully installed PyNaCl-1.5.0 commonmark-0.9.1 cryptography-38.0.1 gputil-1.4.0 imageio-ffmpeg-0.4.4 ipdb-0.13.9 ipython-7.34.0 jedi-0.18.1 kgt-0.4.7 matplotlib-inline-0.1.6 meshzoo-0.9.14 point-cloud-utils-0.27.0 pyspng-0.1.0 rich-12.6.0 tomli-w-1.0.0 x21-0.3.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python==4.5.4.58\n",
            "  Downloading opencv_python-4.5.4.58-cp37-cp37m-manylinux2014_x86_64.whl (60.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.3 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.4.58) (1.21.6)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.6.0.66\n",
            "    Uninstalling opencv-python-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-4.6.0.66\n",
            "Successfully installed opencv-python-4.5.4.58\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nv-tlabs/GET3D\n",
        "%cd GET3D \n",
        "!mkdir cache; \n",
        "!wget https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/metrics/inception-2015-12-05.pkl\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install ninja xatlas gdown\n",
        "!pip install git+https://github.com/NVlabs/nvdiffrast/\n",
        "!pip install meshzoo imageio gputil h5py point-cloud-utils imageio imageio-ffmpeg==0.4.4 pyspng==0.1.0\n",
        "!pip install urllib3\n",
        "!pip install scipy\n",
        "!pip install click\n",
        "!pip install tqdm\n",
        "!pip install opencv-python==4.5.4.58"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GET3D\n",
        "%ls -alh\n",
        "!export PYTHONPATH=$PWD:$PYTHONPATH\n",
        "!export CUDA_VISIBLE_DEVICES=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAibdUFjynzM",
        "outputId": "ac6309ce-43ad-4dae-8305-94d83762dc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GET3D\n",
            "total 92M\n",
            "drwxr-xr-x 15 root root 4.0K Oct 13 18:47 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x  1 root root 4.0K Oct 13 18:47 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x  5 root root 4.0K Oct 13 18:47 \u001b[01;34m3dgan_data_split\u001b[0m/\n",
            "drwxr-xr-x  2 root root 4.0K Oct 13 18:47 \u001b[01;34mcache\u001b[0m/\n",
            "drwxr-xr-x  3 root root 4.0K Oct 13 18:47 \u001b[01;34mdata\u001b[0m/\n",
            "drwxr-xr-x  2 root root 4.0K Oct 13 18:47 \u001b[01;34mdnnlib\u001b[0m/\n",
            "drwxr-xr-x  2 root root 4.0K Oct 13 18:47 \u001b[01;34mdocker\u001b[0m/\n",
            "drwxr-xr-x  3 root root 4.0K Oct 13 18:47 \u001b[01;34mdocs\u001b[0m/\n",
            "drwxr-xr-x  5 root root 4.0K Oct 13 18:47 \u001b[01;34mevaluation_scripts\u001b[0m/\n",
            "drwxr-xr-x  8 root root 4.0K Oct 13 18:47 \u001b[01;34m.git\u001b[0m/\n",
            "-rw-r--r--  1 root root   10 Oct 13 18:47 .gitignore\n",
            "-rw-r--r--  1 root root  92M Oct 15  2021 inception-2015-12-05.pkl\n",
            "-rw-r--r--  1 root root  951 Oct 13 18:47 install_get3d.sh\n",
            "-rw-r--r--  1 root root 4.4K Oct 13 18:47 LICENSE.txt\n",
            "drwxr-xr-x  2 root root 4.0K Oct 13 18:47 \u001b[01;34mmetrics\u001b[0m/\n",
            "-rw-r--r--  1 root root 8.6K Oct 13 18:47 README.md\n",
            "drwxr-xr-x  2 root root 4.0K Oct 13 18:47 \u001b[01;34mrender_shapenet_data\u001b[0m/\n",
            "drwxr-xr-x  3 root root 4.0K Oct 13 18:47 \u001b[01;34mtorch_utils\u001b[0m/\n",
            "-rw-r--r--  1 root root  19K Oct 13 18:47 train_3d.py\n",
            "drwxr-xr-x  3 root root 4.0K Oct 13 18:47 \u001b[01;34mtraining\u001b[0m/\n",
            "drwxr-xr-x  5 root root 4.0K Oct 13 18:47 \u001b[01;34muni_rep\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --folder 1oJ-FmyVYjIwBZKDAQ4N1EEcE9dJjumdW"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4TW-fPByt0d",
        "outputId": "377c9d61-f271-48d6-faef-d2c63c05b313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder list\n",
            "Processing file 1ojTDFqUb99a4s0lkm0oW5aJALi4wDEsO LICENSE.txt\n",
            "Processing file 18UdsemUdKo75GXmQLLVYdcOhNZ3zM215 shapenet_car.pt\n",
            "Processing file 1gXwK3-Y16UBi1-KgTClKcuGv8EFXSeKo shapenet_chair.pt\n",
            "Processing file 1XNWQLCwJ6V_wr2G0dDRsyWyT05b1lWmK shapenet_motorbike.pt\n",
            "Processing file 1msJs8HUR_fjhAJJHrWQkgbwgRW_gFSFq shapenet_table.pt\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ojTDFqUb99a4s0lkm0oW5aJALi4wDEsO\n",
            "To: /content/GET3D/get3d_release/LICENSE.txt\n",
            "100% 20.8k/20.8k [00:00<00:00, 36.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18UdsemUdKo75GXmQLLVYdcOhNZ3zM215\n",
            "To: /content/GET3D/get3d_release/shapenet_car.pt\n",
            "100% 518M/518M [00:06<00:00, 79.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gXwK3-Y16UBi1-KgTClKcuGv8EFXSeKo\n",
            "To: /content/GET3D/get3d_release/shapenet_chair.pt\n",
            "100% 518M/518M [00:03<00:00, 144MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XNWQLCwJ6V_wr2G0dDRsyWyT05b1lWmK\n",
            "To: /content/GET3D/get3d_release/shapenet_motorbike.pt\n",
            "100% 518M/518M [00:08<00:00, 61.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1msJs8HUR_fjhAJJHrWQkgbwgRW_gFSFq\n",
            "To: /content/GET3D/get3d_release/shapenet_table.pt\n",
            "100% 518M/518M [00:06<00:00, 74.6MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running inference on Shapenet Motorbike and generated rendered images \n",
        "# After running, check the results at `save_inference_results/shapenet_motorbike/inference/fakes_000000_00.png` and the folder of some shapes at `save_inference_results/shapenet_motorbike/inference/mesh_pred`\n",
        "!python train_3d.py --outdir=save_inference_results/shapenet_motorbike  --gpus=1 --batch=4 --gamma=40 --data_camera_mode shapenet_motorbike  --dmtet_scale 1.0  --use_shapenet_split 1  --one_3d_generator 1  --fp32 0 --inference_vis 1 --resume_pretrain /content/GET3D/get3d_release/shapenet_motorbike.pt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QumQX4AbC56v",
        "outputId": "a4456136-9e03-4f62-a67e-12f5c685a8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> start\n",
            "==> use shapenet dataset\n",
            "==> ERROR!!!! THIS SHOULD ONLY HAPPEN WHEN USING INFERENCE\n",
            "==> use image path: ./tmp, num images: 1234\n",
            "==> launch training\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.GeneratorDMTETMesh\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 8\n",
            "    },\n",
            "    \"one_3d_generator\": true,\n",
            "    \"n_implicit_layer\": 1,\n",
            "    \"deformation_multiplier\": 1.0,\n",
            "    \"use_style_mixing\": true,\n",
            "    \"dmtet_scale\": 1.0,\n",
            "    \"feat_channel\": 16,\n",
            "    \"mlp_latent_channel\": 32,\n",
            "    \"tri_plane_resolution\": 256,\n",
            "    \"n_views\": 1,\n",
            "    \"render_type\": \"neural_render\",\n",
            "    \"use_tri_plane\": true,\n",
            "    \"tet_res\": 90,\n",
            "    \"geometry_type\": \"conv3d\",\n",
            "    \"data_camera_mode\": \"shapenet_motorbike\",\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"fused_modconv_default\": \"inference_only\"\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"data_camera_mode\": \"shapenet_motorbike\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"architecture\": \"skip\"\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"gamma_mask\": 40.0,\n",
            "    \"r1_gamma\": 40.0,\n",
            "    \"style_mixing_prob\": 0.9,\n",
            "    \"pl_weight\": 0.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"inference_vis\": true,\n",
            "  \"inference_to_generate_textured_mesh\": false,\n",
            "  \"inference_save_interpolation\": false,\n",
            "  \"inference_compute_fid\": false,\n",
            "  \"inference_generate_geo\": false,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./tmp\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1234,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"data_camera_mode\": \"shapenet_motorbike\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"camera_path\": \"./tmp\",\n",
            "    \"split\": \"test\",\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"resume_pretrain\": \"/content/GET3D/get3d_release/shapenet_motorbike.pt\",\n",
            "  \"D_reg_interval\": 16,\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 4,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"metrics\": [\n",
            "    \"fid50k\"\n",
            "  ],\n",
            "  \"total_kimg\": 20000,\n",
            "  \"kimg_per_tick\": 1,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 200,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 1.25,\n",
            "  \"G_reg_interval\": 4,\n",
            "  \"run_dir\": \"save_inference_results/shapenet_motorbike/inference\"\n",
            "}\n",
            "\n",
            "Output directory:    save_inference_results/shapenet_motorbike/inference\n",
            "Number of GPUs:      1\n",
            "Batch size:          4 images\n",
            "Training duration:   20000 kimg\n",
            "Dataset path:        ./tmp\n",
            "Dataset size:        1234 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "==> resume from pretrained path /content/GET3D/get3d_release/shapenet_motorbike.pt\n",
            "==> generate \n",
            "/content/GET3D/training/networks_get3d.py:430: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  camera_theta = torch.range(0, n_camera - 1, device=self.device).unsqueeze(dim=-1) / n_camera * math.pi * 2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running inference on Shapenet Motorbike and generate 3D meshes with textures \n",
        "# After running, check the folder `save_inference_results/shapenet_motorbike/texture_mesh_for_inference`\n",
        "!python train_3d.py --outdir=save_inference_results/shapenet_motorbike  --gpus=1 --batch=4 --gamma=40 --data_camera_mode shapenet_motorbike  --dmtet_scale 1.0  --use_shapenet_split 1  --one_3d_generator 1  --fp32 0 --inference_vis 1 --resume_pretrain /content/GET3D/get3d_release/shapenet_motorbike.pt --inference_to_generate_textured_mesh 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oSOm73dDJj7",
        "outputId": "37fe8f87-41dd-4a04-b90a-b8f558d17a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> start\n",
            "==> use shapenet dataset\n",
            "==> ERROR!!!! THIS SHOULD ONLY HAPPEN WHEN USING INFERENCE\n",
            "==> use image path: ./tmp, num images: 1234\n",
            "==> launch training\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.GeneratorDMTETMesh\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 8\n",
            "    },\n",
            "    \"one_3d_generator\": true,\n",
            "    \"n_implicit_layer\": 1,\n",
            "    \"deformation_multiplier\": 1.0,\n",
            "    \"use_style_mixing\": true,\n",
            "    \"dmtet_scale\": 1.0,\n",
            "    \"feat_channel\": 16,\n",
            "    \"mlp_latent_channel\": 32,\n",
            "    \"tri_plane_resolution\": 256,\n",
            "    \"n_views\": 1,\n",
            "    \"render_type\": \"neural_render\",\n",
            "    \"use_tri_plane\": true,\n",
            "    \"tet_res\": 90,\n",
            "    \"geometry_type\": \"conv3d\",\n",
            "    \"data_camera_mode\": \"shapenet_motorbike\",\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"fused_modconv_default\": \"inference_only\"\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"data_camera_mode\": \"shapenet_motorbike\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"architecture\": \"skip\"\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"gamma_mask\": 40.0,\n",
            "    \"r1_gamma\": 40.0,\n",
            "    \"style_mixing_prob\": 0.9,\n",
            "    \"pl_weight\": 0.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"inference_vis\": true,\n",
            "  \"inference_to_generate_textured_mesh\": true,\n",
            "  \"inference_save_interpolation\": false,\n",
            "  \"inference_compute_fid\": false,\n",
            "  \"inference_generate_geo\": false,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./tmp\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1234,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"data_camera_mode\": \"shapenet_motorbike\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"camera_path\": \"./tmp\",\n",
            "    \"split\": \"test\",\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"resume_pretrain\": \"/content/GET3D/get3d_release/shapenet_motorbike.pt\",\n",
            "  \"D_reg_interval\": 16,\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 4,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"metrics\": [\n",
            "    \"fid50k\"\n",
            "  ],\n",
            "  \"total_kimg\": 20000,\n",
            "  \"kimg_per_tick\": 1,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 200,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 1.25,\n",
            "  \"G_reg_interval\": 4,\n",
            "  \"run_dir\": \"save_inference_results/shapenet_motorbike/inference\"\n",
            "}\n",
            "\n",
            "Output directory:    save_inference_results/shapenet_motorbike/inference\n",
            "Number of GPUs:      1\n",
            "Batch size:          4 images\n",
            "Training duration:   20000 kimg\n",
            "Dataset path:        ./tmp\n",
            "Dataset size:        1234 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "==> resume from pretrained path /content/GET3D/get3d_release/shapenet_motorbike.pt\n",
            "==> generate \n",
            "/content/GET3D/training/networks_get3d.py:430: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  camera_theta = torch.range(0, n_camera - 1, device=self.device).unsqueeze(dim=-1) / n_camera * math.pi * 2.0\n",
            "==> generate inference 3d shapes with texture\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running inference on Shapenet Car and generated rendered images \n",
        "# After running, check the results at `save_inference_results/shapenet_car/inference/fakes_000000_00.png` and the folder of some shapes at `save_inference_results/shapenet_car/inference/mesh_pred`\n",
        "\n",
        "!python train_3d.py --outdir=save_inference_results/shapenet_car  --gpus=1 --batch=4 --gamma=40 --data_camera_mode shapenet_car  --dmtet_scale 1.0  --use_shapenet_split 1  --one_3d_generator 1  --fp32 0 --inference_vis 1 --resume_pretrain /content/GET3D/get3d_release/shapenet_car.pt"
      ],
      "metadata": {
        "id": "KUsu8uSPLbN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9807b1fb-86b7-475e-ebfb-f9240b34597f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> start\n",
            "==> use shapenet dataset\n",
            "==> ERROR!!!! THIS SHOULD ONLY HAPPEN WHEN USING INFERENCE\n",
            "==> use image path: ./tmp, num images: 1234\n",
            "==> launch training\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.GeneratorDMTETMesh\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 8\n",
            "    },\n",
            "    \"one_3d_generator\": true,\n",
            "    \"n_implicit_layer\": 1,\n",
            "    \"deformation_multiplier\": 1.0,\n",
            "    \"use_style_mixing\": true,\n",
            "    \"dmtet_scale\": 1.0,\n",
            "    \"feat_channel\": 16,\n",
            "    \"mlp_latent_channel\": 32,\n",
            "    \"tri_plane_resolution\": 256,\n",
            "    \"n_views\": 1,\n",
            "    \"render_type\": \"neural_render\",\n",
            "    \"use_tri_plane\": true,\n",
            "    \"tet_res\": 90,\n",
            "    \"geometry_type\": \"conv3d\",\n",
            "    \"data_camera_mode\": \"shapenet_car\",\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"fused_modconv_default\": \"inference_only\"\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"data_camera_mode\": \"shapenet_car\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"architecture\": \"skip\"\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"gamma_mask\": 40.0,\n",
            "    \"r1_gamma\": 40.0,\n",
            "    \"style_mixing_prob\": 0.9,\n",
            "    \"pl_weight\": 0.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"inference_vis\": true,\n",
            "  \"inference_to_generate_textured_mesh\": false,\n",
            "  \"inference_save_interpolation\": false,\n",
            "  \"inference_compute_fid\": false,\n",
            "  \"inference_generate_geo\": false,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./tmp\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1234,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"data_camera_mode\": \"shapenet_car\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"camera_path\": \"./tmp\",\n",
            "    \"split\": \"test\",\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"resume_pretrain\": \"/content/GET3D/get3d_release/shapenet_car.pt\",\n",
            "  \"D_reg_interval\": 16,\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 4,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"metrics\": [\n",
            "    \"fid50k\"\n",
            "  ],\n",
            "  \"total_kimg\": 20000,\n",
            "  \"kimg_per_tick\": 1,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 200,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 1.25,\n",
            "  \"G_reg_interval\": 4,\n",
            "  \"run_dir\": \"save_inference_results/shapenet_car/inference\"\n",
            "}\n",
            "\n",
            "Output directory:    save_inference_results/shapenet_car/inference\n",
            "Number of GPUs:      1\n",
            "Batch size:          4 images\n",
            "Training duration:   20000 kimg\n",
            "Dataset path:        ./tmp\n",
            "Dataset size:        1234 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "==> resume from pretrained path /content/GET3D/get3d_release/shapenet_car.pt\n",
            "==> generate \n",
            "/content/GET3D/training/networks_get3d.py:430: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  camera_theta = torch.range(0, n_camera - 1, device=self.device).unsqueeze(dim=-1) / n_camera * math.pi * 2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running inference on Shapenet Chair and generated rendered images \n",
        "# After running, check the results at `save_inference_results/shapenet_chair/inference/fakes_000000_00.png` and the folder of some shapes at `save_inference_results/shapenet_chair/inference/mesh_pred`\n",
        "\n",
        "!python train_3d.py --outdir=save_inference_results/shapenet_chair  --gpus=1 --batch=4 --gamma=400 --data_camera_mode shapenet_chair  --dmtet_scale 0.8  --use_shapenet_split 1  --one_3d_generator 1  --fp32 0 --inference_vis 1 --resume_pretrain /content/GET3D/get3d_release/shapenet_chair.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdG-IZ0bDPFB",
        "outputId": "58d0e58c-f2e1-48dd-cfba-cf05f92b570b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> start\n",
            "==> use shapenet dataset\n",
            "==> ERROR!!!! THIS SHOULD ONLY HAPPEN WHEN USING INFERENCE\n",
            "==> use image path: ./tmp, num images: 1234\n",
            "==> launch training\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.GeneratorDMTETMesh\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 8\n",
            "    },\n",
            "    \"one_3d_generator\": true,\n",
            "    \"n_implicit_layer\": 1,\n",
            "    \"deformation_multiplier\": 1.0,\n",
            "    \"use_style_mixing\": true,\n",
            "    \"dmtet_scale\": 0.8,\n",
            "    \"feat_channel\": 16,\n",
            "    \"mlp_latent_channel\": 32,\n",
            "    \"tri_plane_resolution\": 256,\n",
            "    \"n_views\": 1,\n",
            "    \"render_type\": \"neural_render\",\n",
            "    \"use_tri_plane\": true,\n",
            "    \"tet_res\": 90,\n",
            "    \"geometry_type\": \"conv3d\",\n",
            "    \"data_camera_mode\": \"shapenet_chair\",\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"fused_modconv_default\": \"inference_only\"\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"data_camera_mode\": \"shapenet_chair\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"architecture\": \"skip\"\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"gamma_mask\": 400.0,\n",
            "    \"r1_gamma\": 400.0,\n",
            "    \"style_mixing_prob\": 0.9,\n",
            "    \"pl_weight\": 0.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"inference_vis\": true,\n",
            "  \"inference_to_generate_textured_mesh\": false,\n",
            "  \"inference_save_interpolation\": false,\n",
            "  \"inference_compute_fid\": false,\n",
            "  \"inference_generate_geo\": false,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./tmp\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1234,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"data_camera_mode\": \"shapenet_chair\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"camera_path\": \"./tmp\",\n",
            "    \"split\": \"test\",\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"resume_pretrain\": \"/content/GET3D/get3d_release/shapenet_chair.pt\",\n",
            "  \"D_reg_interval\": 16,\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 4,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"metrics\": [\n",
            "    \"fid50k\"\n",
            "  ],\n",
            "  \"total_kimg\": 20000,\n",
            "  \"kimg_per_tick\": 1,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 200,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 1.25,\n",
            "  \"G_reg_interval\": 4,\n",
            "  \"run_dir\": \"save_inference_results/shapenet_chair/inference\"\n",
            "}\n",
            "\n",
            "Output directory:    save_inference_results/shapenet_chair/inference\n",
            "Number of GPUs:      1\n",
            "Batch size:          4 images\n",
            "Training duration:   20000 kimg\n",
            "Dataset path:        ./tmp\n",
            "Dataset size:        1234 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "==> resume from pretrained path /content/GET3D/get3d_release/shapenet_chair.pt\n",
            "==> generate \n",
            "/content/GET3D/training/networks_get3d.py:430: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  camera_theta = torch.range(0, n_camera - 1, device=self.device).unsqueeze(dim=-1) / n_camera * math.pi * 2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running inference on Shapenet Chair and generated rendered images \n",
        "# After running, check the results at `save_inference_results/shapenet_table/inference/fakes_000000_00.png` and the folder of some shapes at `save_inference_results/shapenet_table/inference/mesh_pred`\n",
        "!python train_3d.py --outdir=save_inference_results/shapenet_table  --gpus=1 --batch=4 --gamma=400 --data_camera_mode shapenet_chair  --dmtet_scale 0.8  --use_shapenet_split 1  --one_3d_generator 1  --fp32 0 --inference_vis 1 --resume_pretrain /content/GET3D/get3d_release/shapenet_table.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNV78egELgO_",
        "outputId": "dc19f8da-0bb7-41e6-98dd-5198412ee19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> start\n",
            "==> use shapenet dataset\n",
            "==> ERROR!!!! THIS SHOULD ONLY HAPPEN WHEN USING INFERENCE\n",
            "==> use image path: ./tmp, num images: 1234\n",
            "==> launch training\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.GeneratorDMTETMesh\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 8\n",
            "    },\n",
            "    \"one_3d_generator\": true,\n",
            "    \"n_implicit_layer\": 1,\n",
            "    \"deformation_multiplier\": 1.0,\n",
            "    \"use_style_mixing\": true,\n",
            "    \"dmtet_scale\": 0.8,\n",
            "    \"feat_channel\": 16,\n",
            "    \"mlp_latent_channel\": 32,\n",
            "    \"tri_plane_resolution\": 256,\n",
            "    \"n_views\": 1,\n",
            "    \"render_type\": \"neural_render\",\n",
            "    \"use_tri_plane\": true,\n",
            "    \"tet_res\": 90,\n",
            "    \"geometry_type\": \"conv3d\",\n",
            "    \"data_camera_mode\": \"shapenet_chair\",\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"fused_modconv_default\": \"inference_only\"\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"data_camera_mode\": \"shapenet_chair\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"architecture\": \"skip\"\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"gamma_mask\": 400.0,\n",
            "    \"r1_gamma\": 400.0,\n",
            "    \"style_mixing_prob\": 0.9,\n",
            "    \"pl_weight\": 0.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"inference_vis\": true,\n",
            "  \"inference_to_generate_textured_mesh\": false,\n",
            "  \"inference_save_interpolation\": false,\n",
            "  \"inference_compute_fid\": false,\n",
            "  \"inference_generate_geo\": false,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./tmp\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1234,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"data_camera_mode\": \"shapenet_chair\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"camera_path\": \"./tmp\",\n",
            "    \"split\": \"test\",\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"resume_pretrain\": \"/content/GET3D/get3d_release/shapenet_table.pt\",\n",
            "  \"D_reg_interval\": 16,\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 4,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"metrics\": [\n",
            "    \"fid50k\"\n",
            "  ],\n",
            "  \"total_kimg\": 20000,\n",
            "  \"kimg_per_tick\": 1,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 200,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 1.25,\n",
            "  \"G_reg_interval\": 4,\n",
            "  \"run_dir\": \"save_inference_results/shapenet_table/inference\"\n",
            "}\n",
            "\n",
            "Output directory:    save_inference_results/shapenet_table/inference\n",
            "Number of GPUs:      1\n",
            "Batch size:          4 images\n",
            "Training duration:   20000 kimg\n",
            "Dataset path:        ./tmp\n",
            "Dataset size:        1234 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "==> resume from pretrained path /content/GET3D/get3d_release/shapenet_table.pt\n",
            "==> generate \n",
            "/content/GET3D/training/networks_get3d.py:430: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  camera_theta = torch.range(0, n_camera - 1, device=self.device).unsqueeze(dim=-1) / n_camera * math.pi * 2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running inference on Shapenet Car and generated 3D meshes with textures\n",
        "# After running, check the results at `save_inference_results/shapenet_car/inference/texture_mesh_for_inference`\n",
        "\n",
        "!python train_3d.py --outdir=save_inference_results/shapenet_car  --gpus=1 --batch=4 --gamma=40 --data_camera_mode shapenet_car  --dmtet_scale 1.0  --use_shapenet_split 1  --one_3d_generator 1  --fp32 0 --inference_vis 1 --resume_pretrain /content/GET3D/get3d_release/shapenet_car.pt --inference_to_generate_textured_mesh 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnOv76ptgI4k",
        "outputId": "813f2bf9-3b86-443a-ad9e-c0f046c22859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> start\n",
            "==> use shapenet dataset\n",
            "==> ERROR!!!! THIS SHOULD ONLY HAPPEN WHEN USING INFERENCE\n",
            "==> use image path: ./tmp, num images: 1234\n",
            "==> launch training\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.GeneratorDMTETMesh\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 8\n",
            "    },\n",
            "    \"one_3d_generator\": true,\n",
            "    \"n_implicit_layer\": 1,\n",
            "    \"deformation_multiplier\": 1.0,\n",
            "    \"use_style_mixing\": true,\n",
            "    \"dmtet_scale\": 1.0,\n",
            "    \"feat_channel\": 16,\n",
            "    \"mlp_latent_channel\": 32,\n",
            "    \"tri_plane_resolution\": 256,\n",
            "    \"n_views\": 1,\n",
            "    \"render_type\": \"neural_render\",\n",
            "    \"use_tri_plane\": true,\n",
            "    \"tet_res\": 90,\n",
            "    \"geometry_type\": \"conv3d\",\n",
            "    \"data_camera_mode\": \"shapenet_car\",\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"fused_modconv_default\": \"inference_only\"\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"data_camera_mode\": \"shapenet_car\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"architecture\": \"skip\"\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"gamma_mask\": 40.0,\n",
            "    \"r1_gamma\": 40.0,\n",
            "    \"style_mixing_prob\": 0.9,\n",
            "    \"pl_weight\": 0.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"inference_vis\": true,\n",
            "  \"inference_to_generate_textured_mesh\": true,\n",
            "  \"inference_save_interpolation\": false,\n",
            "  \"inference_compute_fid\": false,\n",
            "  \"inference_generate_geo\": false,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./tmp\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1234,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"data_camera_mode\": \"shapenet_car\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"camera_path\": \"./tmp\",\n",
            "    \"split\": \"test\",\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"resume_pretrain\": \"/content/GET3D/get3d_release/shapenet_car.pt\",\n",
            "  \"D_reg_interval\": 16,\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 4,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"metrics\": [\n",
            "    \"fid50k\"\n",
            "  ],\n",
            "  \"total_kimg\": 20000,\n",
            "  \"kimg_per_tick\": 1,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 200,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 1.25,\n",
            "  \"G_reg_interval\": 4,\n",
            "  \"run_dir\": \"save_inference_results/shapenet_car/inference\"\n",
            "}\n",
            "\n",
            "Output directory:    save_inference_results/shapenet_car/inference\n",
            "Number of GPUs:      1\n",
            "Batch size:          4 images\n",
            "Training duration:   20000 kimg\n",
            "Dataset path:        ./tmp\n",
            "Dataset size:        1234 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "==> resume from pretrained path /content/GET3D/get3d_release/shapenet_car.pt\n",
            "==> generate \n",
            "/content/GET3D/training/networks_get3d.py:430: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  camera_theta = torch.range(0, n_camera - 1, device=self.device).unsqueeze(dim=-1) / n_camera * math.pi * 2.0\n",
            "==> generate inference 3d shapes with texture\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running inference on Shapenet Chair and generated 3D meshes with textures\n",
        "# After running, check the results at `save_inference_results/shapenet_chair/inference/texture_mesh_for_inference`\n",
        "\n",
        "!python train_3d.py --outdir=save_inference_results/shapenet_chair  --gpus=1 --batch=4 --gamma=400 --data_camera_mode shapenet_chair  --dmtet_scale 0.8  --use_shapenet_split 1  --one_3d_generator 1  --fp32 0 --inference_vis 1 --resume_pretrain /content/GET3D/get3d_release/shapenet_chair.pt --inference_to_generate_textured_mesh 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wHYZo-glf19",
        "outputId": "ea8ef6fa-cf20-40bf-a00e-e3708463112c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> start\n",
            "==> use shapenet dataset\n",
            "==> ERROR!!!! THIS SHOULD ONLY HAPPEN WHEN USING INFERENCE\n",
            "==> use image path: ./tmp, num images: 1234\n",
            "==> launch training\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.GeneratorDMTETMesh\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 8\n",
            "    },\n",
            "    \"one_3d_generator\": true,\n",
            "    \"n_implicit_layer\": 1,\n",
            "    \"deformation_multiplier\": 1.0,\n",
            "    \"use_style_mixing\": true,\n",
            "    \"dmtet_scale\": 0.8,\n",
            "    \"feat_channel\": 16,\n",
            "    \"mlp_latent_channel\": 32,\n",
            "    \"tri_plane_resolution\": 256,\n",
            "    \"n_views\": 1,\n",
            "    \"render_type\": \"neural_render\",\n",
            "    \"use_tri_plane\": true,\n",
            "    \"tet_res\": 90,\n",
            "    \"geometry_type\": \"conv3d\",\n",
            "    \"data_camera_mode\": \"shapenet_chair\",\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"fused_modconv_default\": \"inference_only\"\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_get3d.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"data_camera_mode\": \"shapenet_chair\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"architecture\": \"skip\"\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"gamma_mask\": 400.0,\n",
            "    \"r1_gamma\": 400.0,\n",
            "    \"style_mixing_prob\": 0.9,\n",
            "    \"pl_weight\": 0.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"inference_vis\": true,\n",
            "  \"inference_to_generate_textured_mesh\": true,\n",
            "  \"inference_save_interpolation\": false,\n",
            "  \"inference_compute_fid\": false,\n",
            "  \"inference_generate_geo\": false,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./tmp\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1234,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"data_camera_mode\": \"shapenet_chair\",\n",
            "    \"add_camera_cond\": true,\n",
            "    \"camera_path\": \"./tmp\",\n",
            "    \"split\": \"test\",\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"resume_pretrain\": \"/content/GET3D/get3d_release/shapenet_chair.pt\",\n",
            "  \"D_reg_interval\": 16,\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 4,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"metrics\": [\n",
            "    \"fid50k\"\n",
            "  ],\n",
            "  \"total_kimg\": 20000,\n",
            "  \"kimg_per_tick\": 1,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 200,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 1.25,\n",
            "  \"G_reg_interval\": 4,\n",
            "  \"run_dir\": \"save_inference_results/shapenet_chair/inference\"\n",
            "}\n",
            "\n",
            "Output directory:    save_inference_results/shapenet_chair/inference\n",
            "Number of GPUs:      1\n",
            "Batch size:          4 images\n",
            "Training duration:   20000 kimg\n",
            "Dataset path:        ./tmp\n",
            "Dataset size:        1234 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "==> resume from pretrained path /content/GET3D/get3d_release/shapenet_chair.pt\n",
            "==> generate \n",
            "/content/GET3D/training/networks_get3d.py:430: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  camera_theta = torch.range(0, n_camera - 1, device=self.device).unsqueeze(dim=-1) / n_camera * math.pi * 2.0\n",
            "==> generate inference 3d shapes with texture\n"
          ]
        }
      ]
    }
  ]
}